{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f8dd13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:54:08.359694Z",
     "iopub.status.busy": "2023-04-26T16:54:08.358579Z",
     "iopub.status.idle": "2023-04-26T16:54:19.083486Z",
     "shell.execute_reply": "2023-04-26T16:54:19.082078Z"
    },
    "papermill": {
     "duration": 10.73462,
     "end_time": "2023-04-26T16:54:19.086405",
     "exception": false,
     "start_time": "2023-04-26T16:54:08.351785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\r\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\r\n",
      "Collecting textsearch>=0.0.21\r\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\r\n",
      "Collecting pyahocorasick\r\n",
      "  Downloading pyahocorasick-2.0.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (101 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting anyascii\r\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\r\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24c68ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:54:19.097568Z",
     "iopub.status.busy": "2023-04-26T16:54:19.097237Z",
     "iopub.status.idle": "2023-04-26T16:54:21.664764Z",
     "shell.execute_reply": "2023-04-26T16:54:21.663555Z"
    },
    "papermill": {
     "duration": 2.576466,
     "end_time": "2023-04-26T16:54:21.667828",
     "exception": false,
     "start_time": "2023-04-26T16:54:19.091362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\r\n",
      "  warn(RuntimeWarning(msg))\r\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\r\n",
      "[nltk_data]   Package wordnet is already up-to-date!\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m nltk.downloader wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44060005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:54:21.679199Z",
     "iopub.status.busy": "2023-04-26T16:54:21.678844Z",
     "iopub.status.idle": "2023-04-26T16:54:22.931304Z",
     "shell.execute_reply": "2023-04-26T16:54:22.929894Z"
    },
    "papermill": {
     "duration": 1.261558,
     "end_time": "2023-04-26T16:54:22.934397",
     "exception": false,
     "start_time": "2023-04-26T16:54:21.672839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /usr/share/nltk_data/corpora/wordnet.zip\r\n",
      "   creating: /usr/share/nltk_data/corpora/wordnet/\r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/README  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925e99c2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-26T16:54:22.948439Z",
     "iopub.status.busy": "2023-04-26T16:54:22.947781Z",
     "iopub.status.idle": "2023-04-26T16:54:23.556051Z",
     "shell.execute_reply": "2023-04-26T16:54:23.554497Z"
    },
    "papermill": {
     "duration": 0.617994,
     "end_time": "2023-04-26T16:54:23.558434",
     "exception": false,
     "start_time": "2023-04-26T16:54:22.940440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings.zip\n",
      "/kaggle/input/quora-insincere-questions-classification/train.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Libraries to drop english words and tokenize the text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import contractions\n",
    "import string\n",
    "\n",
    "# Libraries for TF-IDF model and Logistic Regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e2ba04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:54:23.571261Z",
     "iopub.status.busy": "2023-04-26T16:54:23.570898Z",
     "iopub.status.idle": "2023-04-26T16:54:23.652741Z",
     "shell.execute_reply": "2023-04-26T16:54:23.651566Z"
    },
    "papermill": {
     "duration": 0.091469,
     "end_time": "2023-04-26T16:54:23.655494",
     "exception": false,
     "start_time": "2023-04-26T16:54:23.564025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12211a28",
   "metadata": {
    "papermill": {
     "duration": 0.005012,
     "end_time": "2023-04-26T16:54:23.665703",
     "exception": false,
     "start_time": "2023-04-26T16:54:23.660691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# <font color=green>Preprocess the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86dcd428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:54:23.677717Z",
     "iopub.status.busy": "2023-04-26T16:54:23.676806Z",
     "iopub.status.idle": "2023-04-26T16:54:29.371884Z",
     "shell.execute_reply": "2023-04-26T16:54:29.370806Z"
    },
    "papermill": {
     "duration": 5.703749,
     "end_time": "2023-04-26T16:54:29.374485",
     "exception": false,
     "start_time": "2023-04-26T16:54:23.670736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataFrame with Test data\n",
    "test_df = pd.read_csv(f'/kaggle/input/quora-insincere-questions-classification/test.csv')\n",
    "# DataFrame with Train Data\n",
    "train_df = pd.read_csv(f'/kaggle/input/quora-insincere-questions-classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "685b88e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:54:29.386886Z",
     "iopub.status.busy": "2023-04-26T16:54:29.386274Z",
     "iopub.status.idle": "2023-04-26T16:54:29.393390Z",
     "shell.execute_reply": "2023-04-26T16:54:29.392305Z"
    },
    "papermill": {
     "duration": 0.015682,
     "end_time": "2023-04-26T16:54:29.395742",
     "exception": false,
     "start_time": "2023-04-26T16:54:29.380060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  The Function for text preprocessing\n",
    "def tokenize_string(text):\n",
    "\n",
    "    # Before lemmatizing replace all constructions with normal words\n",
    "    text_upd = contractions.fix(text)\n",
    "\n",
    "    # Tokenize the data and use only lower letters\n",
    "    words = word_tokenize(text_upd.lower())\n",
    "    \n",
    "    # Create a lemmatizer object\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(word, pos = \"v\") for word in words] \n",
    "    \n",
    "    # # Get rid of punctuation\n",
    "    words = [word for word in lemmas if word not in string.punctuation]\n",
    "    \n",
    "    # Remove stop words\n",
    "    # Stop words corpus (179 in total)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46f7494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:54:29.407088Z",
     "iopub.status.busy": "2023-04-26T16:54:29.406790Z",
     "iopub.status.idle": "2023-04-26T17:05:38.132352Z",
     "shell.execute_reply": "2023-04-26T17:05:38.130862Z"
    },
    "papermill": {
     "duration": 668.734438,
     "end_time": "2023-04-26T17:05:38.135206",
     "exception": false,
     "start_time": "2023-04-26T16:54:29.400768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have just started updatind test_df\n",
      "I have just started updatind train_df\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the series for test data\n",
    "print('I have just started updatind test_df')\n",
    "test_df['Preprocessed_text'] = test_df.question_text.apply(tokenize_string)\n",
    "\n",
    "# Tokenizing the series for train data\n",
    "print('I have just started updatind train_df')\n",
    "train_df['Preprocessed_text'] = train_df.question_text.apply(tokenize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34168d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T17:05:38.148921Z",
     "iopub.status.busy": "2023-04-26T17:05:38.147338Z",
     "iopub.status.idle": "2023-04-26T17:05:38.165006Z",
     "shell.execute_reply": "2023-04-26T17:05:38.164048Z"
    },
    "papermill": {
     "duration": 0.026363,
     "end_time": "2023-04-26T17:05:38.167409",
     "exception": false,
     "start_time": "2023-04-26T17:05:38.141046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>Preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "      <td>[quebec, nationalists, see, province, nation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "      <td>[adopt, dog, would, encourage, people, adopt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[velocity, affect, time, velocity, affect, spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "      <td>[otto, von, guericke, use, magdeburg, hemisphe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[convert, montra, helicon, mountain, bike, cha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target                                  Preprocessed_text  \n",
       "0       0  [quebec, nationalists, see, province, nation, ...  \n",
       "1       0  [adopt, dog, would, encourage, people, adopt, ...  \n",
       "2       0  [velocity, affect, time, velocity, affect, spa...  \n",
       "3       0  [otto, von, guericke, use, magdeburg, hemisphe...  \n",
       "4       0  [convert, montra, helicon, mountain, bike, cha...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2781553",
   "metadata": {
    "papermill": {
     "duration": 0.005164,
     "end_time": "2023-04-26T17:05:38.177904",
     "exception": false,
     "start_time": "2023-04-26T17:05:38.172740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# <font color=green>Creating baseline model based on Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04ce0287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T17:05:38.189611Z",
     "iopub.status.busy": "2023-04-26T17:05:38.189327Z",
     "iopub.status.idle": "2023-04-26T17:05:38.992482Z",
     "shell.execute_reply": "2023-04-26T17:05:38.991404Z"
    },
    "papermill": {
     "duration": 0.811739,
     "end_time": "2023-04-26T17:05:38.994915",
     "exception": false,
     "start_time": "2023-04-26T17:05:38.183176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['text'] = train_df.Preprocessed_text.apply(lambda x: ' '.join(x))\n",
    "test_df['text'] = test_df.Preprocessed_text.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffd86672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T17:05:39.007522Z",
     "iopub.status.busy": "2023-04-26T17:05:39.007200Z",
     "iopub.status.idle": "2023-04-26T17:05:39.012553Z",
     "shell.execute_reply": "2023-04-26T17:05:39.011610Z"
    },
    "papermill": {
     "duration": 0.014064,
     "end_time": "2023-04-26T17:05:39.014690",
     "exception": false,
     "start_time": "2023-04-26T17:05:39.000626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00e4bb49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T17:05:39.026713Z",
     "iopub.status.busy": "2023-04-26T17:05:39.026425Z",
     "iopub.status.idle": "2023-04-26T17:05:53.210447Z",
     "shell.execute_reply": "2023-04-26T17:05:53.209374Z"
    },
    "papermill": {
     "duration": 14.193314,
     "end_time": "2023-04-26T17:05:53.213313",
     "exception": false,
     "start_time": "2023-04-26T17:05:39.019999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorize the sentences\n",
    "X_train = vectorizer.fit_transform(train_df['text'])\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "y_train = train_df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e26c3e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T17:05:53.225685Z",
     "iopub.status.busy": "2023-04-26T17:05:53.225369Z",
     "iopub.status.idle": "2023-04-26T17:06:13.684730Z",
     "shell.execute_reply": "2023-04-26T17:06:13.683657Z"
    },
    "papermill": {
     "duration": 20.468299,
     "end_time": "2023-04-26T17:06:13.687247",
     "exception": false,
     "start_time": "2023-04-26T17:05:53.218948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a logistic regression model on the vectorized data\n",
    "clf = LogisticRegression(random_state=0, solver='liblinear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f22651f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T17:06:13.701103Z",
     "iopub.status.busy": "2023-04-26T17:06:13.699534Z",
     "iopub.status.idle": "2023-04-26T17:06:13.716629Z",
     "shell.execute_reply": "2023-04-26T17:06:13.715643Z"
    },
    "papermill": {
     "duration": 0.026068,
     "end_time": "2023-04-26T17:06:13.719050",
     "exception": false,
     "start_time": "2023-04-26T17:06:13.692982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a prediction on new data\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a572fd3b",
   "metadata": {
    "papermill": {
     "duration": 0.005233,
     "end_time": "2023-04-26T17:06:13.729804",
     "exception": false,
     "start_time": "2023-04-26T17:06:13.724571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# <font color=green>Making the final file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff337b92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T17:06:13.741641Z",
     "iopub.status.busy": "2023-04-26T17:06:13.741320Z",
     "iopub.status.idle": "2023-04-26T17:06:14.261945Z",
     "shell.execute_reply": "2023-04-26T17:06:14.260870Z"
    },
    "papermill": {
     "duration": 0.529526,
     "end_time": "2023-04-26T17:06:14.264599",
     "exception": false,
     "start_time": "2023-04-26T17:06:13.735073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'qid': test_df.qid, 'prediction': y_pred}).to_csv('submission_logistic_reg.csv', index='qid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64a654d",
   "metadata": {
    "papermill": {
     "duration": 0.00519,
     "end_time": "2023-04-26T17:06:14.276131",
     "exception": false,
     "start_time": "2023-04-26T17:06:14.270941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 737.089146,
   "end_time": "2023-04-26T17:06:16.111486",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-26T16:53:59.022340",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
