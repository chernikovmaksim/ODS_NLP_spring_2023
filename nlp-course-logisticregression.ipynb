{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86baea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:26:14.870512Z",
     "iopub.status.busy": "2023-04-27T15:26:14.869922Z",
     "iopub.status.idle": "2023-04-27T15:26:14.876200Z",
     "shell.execute_reply": "2023-04-27T15:26:14.875160Z"
    },
    "papermill": {
     "duration": 0.020778,
     "end_time": "2023-04-27T15:26:14.884543",
     "exception": false,
     "start_time": "2023-04-27T15:26:14.863765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba14769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:26:14.892378Z",
     "iopub.status.busy": "2023-04-27T15:26:14.892095Z",
     "iopub.status.idle": "2023-04-27T15:26:14.896130Z",
     "shell.execute_reply": "2023-04-27T15:26:14.895082Z"
    },
    "papermill": {
     "duration": 0.010264,
     "end_time": "2023-04-27T15:26:14.898250",
     "exception": false,
     "start_time": "2023-04-27T15:26:14.887986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python3 -m nltk.downloader wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af644913",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-27T15:26:14.907282Z",
     "iopub.status.busy": "2023-04-27T15:26:14.905701Z",
     "iopub.status.idle": "2023-04-27T15:26:16.146547Z",
     "shell.execute_reply": "2023-04-27T15:26:16.145373Z"
    },
    "papermill": {
     "duration": 1.247762,
     "end_time": "2023-04-27T15:26:16.149204",
     "exception": false,
     "start_time": "2023-04-27T15:26:14.901442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings.zip\n",
      "/kaggle/input/quora-insincere-questions-classification/train.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Libraries to drop english words and tokenize the text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# import contractions\n",
    "import string\n",
    "\n",
    "# Libraries for TF-IDF model and Logistic Regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3141c534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:26:16.157717Z",
     "iopub.status.busy": "2023-04-27T15:26:16.157123Z",
     "iopub.status.idle": "2023-04-27T15:26:17.399179Z",
     "shell.execute_reply": "2023-04-27T15:26:17.397922Z"
    },
    "papermill": {
     "duration": 1.248947,
     "end_time": "2023-04-27T15:26:17.401657",
     "exception": false,
     "start_time": "2023-04-27T15:26:16.152710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /usr/share/nltk_data/corpora/wordnet.zip\r\n",
      "   creating: /usr/share/nltk_data/corpora/wordnet/\r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/README  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c14ba078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:26:17.410835Z",
     "iopub.status.busy": "2023-04-27T15:26:17.410525Z",
     "iopub.status.idle": "2023-04-27T15:26:17.414962Z",
     "shell.execute_reply": "2023-04-27T15:26:17.413852Z"
    },
    "papermill": {
     "duration": 0.011577,
     "end_time": "2023-04-27T15:26:17.417114",
     "exception": false,
     "start_time": "2023-04-27T15:26:17.405537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c00df90",
   "metadata": {
    "papermill": {
     "duration": 0.003453,
     "end_time": "2023-04-27T15:26:17.424175",
     "exception": false,
     "start_time": "2023-04-27T15:26:17.420722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# <font color=green>Preprocess the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9229bf26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:26:17.433123Z",
     "iopub.status.busy": "2023-04-27T15:26:17.432246Z",
     "iopub.status.idle": "2023-04-27T15:26:22.785837Z",
     "shell.execute_reply": "2023-04-27T15:26:22.784795Z"
    },
    "papermill": {
     "duration": 5.360798,
     "end_time": "2023-04-27T15:26:22.788501",
     "exception": false,
     "start_time": "2023-04-27T15:26:17.427703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataFrame with Test data\n",
    "test_df = pd.read_csv(f'/kaggle/input/quora-insincere-questions-classification/test.csv')\n",
    "# DataFrame with Train Data\n",
    "train_df = pd.read_csv(f'/kaggle/input/quora-insincere-questions-classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f303435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:26:22.798091Z",
     "iopub.status.busy": "2023-04-27T15:26:22.797224Z",
     "iopub.status.idle": "2023-04-27T15:26:22.803878Z",
     "shell.execute_reply": "2023-04-27T15:26:22.803051Z"
    },
    "papermill": {
     "duration": 0.01368,
     "end_time": "2023-04-27T15:26:22.806120",
     "exception": false,
     "start_time": "2023-04-27T15:26:22.792440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  The Function for text preprocessing\n",
    "def tokenize_string(text):\n",
    "\n",
    "    # Before lemmatizing replace all constructions with normal words\n",
    "#     text_upd = contractions.fix(text)\n",
    "\n",
    "    # Tokenize the data and use only lower letters\n",
    "    words = word_tokenize(text.lower())\n",
    "    \n",
    "    # Create a lemmatizer object\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(word, pos = \"v\") for word in words] \n",
    "    \n",
    "    # # Get rid of punctuation\n",
    "    words = [word for word in lemmas if word not in string.punctuation]\n",
    "    \n",
    "    # Remove stop words\n",
    "    # Stop words corpus (179 in total)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e1e467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:26:22.814888Z",
     "iopub.status.busy": "2023-04-27T15:26:22.814605Z",
     "iopub.status.idle": "2023-04-27T15:36:53.777395Z",
     "shell.execute_reply": "2023-04-27T15:36:53.776202Z"
    },
    "papermill": {
     "duration": 630.970629,
     "end_time": "2023-04-27T15:36:53.780465",
     "exception": false,
     "start_time": "2023-04-27T15:26:22.809836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have just started updatind test_df\n",
      "I have just started updatind train_df\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the series for test data\n",
    "print('I have just started updatind test_df')\n",
    "test_df['Preprocessed_text'] = test_df.question_text.apply(tokenize_string)\n",
    "\n",
    "# Tokenizing the series for train data\n",
    "print('I have just started updatind train_df')\n",
    "train_df['Preprocessed_text'] = train_df.question_text.apply(tokenize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ddd2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:36:53.790534Z",
     "iopub.status.busy": "2023-04-27T15:36:53.790223Z",
     "iopub.status.idle": "2023-04-27T15:36:53.810689Z",
     "shell.execute_reply": "2023-04-27T15:36:53.809586Z"
    },
    "papermill": {
     "duration": 0.028305,
     "end_time": "2023-04-27T15:36:53.813375",
     "exception": false,
     "start_time": "2023-04-27T15:36:53.785070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>Preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "      <td>[many, women, become, rude, arrogant, get, lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "      <td>[apply, rv, college, engineer, bms, college, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "      <td>[really, like, nurse, practitioner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "      <td>[entrepreneurs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "      <td>[education, really, make, good, people, nowadays]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...   \n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...   \n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...   \n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?   \n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?   \n",
       "\n",
       "                                   Preprocessed_text  \n",
       "0  [many, women, become, rude, arrogant, get, lit...  \n",
       "1  [apply, rv, college, engineer, bms, college, e...  \n",
       "2                [really, like, nurse, practitioner]  \n",
       "3                                    [entrepreneurs]  \n",
       "4  [education, really, make, good, people, nowadays]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd6d1ac",
   "metadata": {
    "papermill": {
     "duration": 0.00397,
     "end_time": "2023-04-27T15:36:53.821520",
     "exception": false,
     "start_time": "2023-04-27T15:36:53.817550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# <font color=green>Creating baseline model based on Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3755f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:36:53.830941Z",
     "iopub.status.busy": "2023-04-27T15:36:53.830664Z",
     "iopub.status.idle": "2023-04-27T15:36:54.640838Z",
     "shell.execute_reply": "2023-04-27T15:36:54.639787Z"
    },
    "papermill": {
     "duration": 0.817775,
     "end_time": "2023-04-27T15:36:54.643400",
     "exception": false,
     "start_time": "2023-04-27T15:36:53.825625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['text'] = train_df.Preprocessed_text.apply(lambda x: ' '.join(x))\n",
    "test_df['text'] = test_df.Preprocessed_text.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3cf811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:36:54.653503Z",
     "iopub.status.busy": "2023-04-27T15:36:54.653203Z",
     "iopub.status.idle": "2023-04-27T15:36:54.658632Z",
     "shell.execute_reply": "2023-04-27T15:36:54.657693Z"
    },
    "papermill": {
     "duration": 0.0129,
     "end_time": "2023-04-27T15:36:54.660706",
     "exception": false,
     "start_time": "2023-04-27T15:36:54.647806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fcbe110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:36:54.670590Z",
     "iopub.status.busy": "2023-04-27T15:36:54.670319Z",
     "iopub.status.idle": "2023-04-27T15:37:08.785415Z",
     "shell.execute_reply": "2023-04-27T15:37:08.784385Z"
    },
    "papermill": {
     "duration": 14.12311,
     "end_time": "2023-04-27T15:37:08.788281",
     "exception": false,
     "start_time": "2023-04-27T15:36:54.665171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorize the sentences\n",
    "X_train = vectorizer.fit_transform(train_df['text'])\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "y_train = train_df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f751eca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:37:08.798463Z",
     "iopub.status.busy": "2023-04-27T15:37:08.798160Z",
     "iopub.status.idle": "2023-04-27T15:37:29.127038Z",
     "shell.execute_reply": "2023-04-27T15:37:29.126026Z"
    },
    "papermill": {
     "duration": 20.336855,
     "end_time": "2023-04-27T15:37:29.129665",
     "exception": false,
     "start_time": "2023-04-27T15:37:08.792810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a logistic regression model on the vectorized data\n",
    "clf = LogisticRegression(random_state=0, solver='liblinear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4d5fd69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:37:29.140586Z",
     "iopub.status.busy": "2023-04-27T15:37:29.140265Z",
     "iopub.status.idle": "2023-04-27T15:37:29.155650Z",
     "shell.execute_reply": "2023-04-27T15:37:29.154704Z"
    },
    "papermill": {
     "duration": 0.023199,
     "end_time": "2023-04-27T15:37:29.157753",
     "exception": false,
     "start_time": "2023-04-27T15:37:29.134554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a prediction on new data\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a8b95",
   "metadata": {
    "papermill": {
     "duration": 0.004123,
     "end_time": "2023-04-27T15:37:29.166414",
     "exception": false,
     "start_time": "2023-04-27T15:37:29.162291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# <font color=green>Making the final file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "247d7db5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T15:37:29.176852Z",
     "iopub.status.busy": "2023-04-27T15:37:29.175991Z",
     "iopub.status.idle": "2023-04-27T15:37:29.433340Z",
     "shell.execute_reply": "2023-04-27T15:37:29.432294Z"
    },
    "papermill": {
     "duration": 0.265282,
     "end_time": "2023-04-27T15:37:29.436096",
     "exception": false,
     "start_time": "2023-04-27T15:37:29.170814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'qid': test_df.qid, 'prediction': y_pred}).set_index('qid').to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 685.209301,
   "end_time": "2023-04-27T15:37:31.165713",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-27T15:26:05.956412",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
