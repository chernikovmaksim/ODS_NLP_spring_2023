{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80bec35a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:35:11.725417Z",
     "iopub.status.busy": "2023-04-29T09:35:11.724332Z",
     "iopub.status.idle": "2023-04-29T09:35:11.730167Z",
     "shell.execute_reply": "2023-04-29T09:35:11.729121Z"
    },
    "papermill": {
     "duration": 0.01423,
     "end_time": "2023-04-29T09:35:11.732742",
     "exception": false,
     "start_time": "2023-04-29T09:35:11.718512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d689d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:35:11.740465Z",
     "iopub.status.busy": "2023-04-29T09:35:11.740187Z",
     "iopub.status.idle": "2023-04-29T09:35:11.744319Z",
     "shell.execute_reply": "2023-04-29T09:35:11.743285Z"
    },
    "papermill": {
     "duration": 0.01016,
     "end_time": "2023-04-29T09:35:11.746327",
     "exception": false,
     "start_time": "2023-04-29T09:35:11.736167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python3 -m nltk.downloader wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0ffd3e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-29T09:35:11.754215Z",
     "iopub.status.busy": "2023-04-29T09:35:11.753695Z",
     "iopub.status.idle": "2023-04-29T09:35:13.003811Z",
     "shell.execute_reply": "2023-04-29T09:35:13.002630Z"
    },
    "papermill": {
     "duration": 1.256516,
     "end_time": "2023-04-29T09:35:13.006078",
     "exception": false,
     "start_time": "2023-04-29T09:35:11.749562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings.zip\n",
      "/kaggle/input/quora-insincere-questions-classification/train.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Libraries to drop english words and tokenize the text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# import contractions\n",
    "import string\n",
    "\n",
    "# Libraries for TF-IDF model and Logistic Regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1136111b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:35:13.015546Z",
     "iopub.status.busy": "2023-04-29T09:35:13.013971Z",
     "iopub.status.idle": "2023-04-29T09:35:14.253035Z",
     "shell.execute_reply": "2023-04-29T09:35:14.251832Z"
    },
    "papermill": {
     "duration": 1.246007,
     "end_time": "2023-04-29T09:35:14.255625",
     "exception": false,
     "start_time": "2023-04-29T09:35:13.009618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /usr/share/nltk_data/corpora/wordnet.zip\r\n",
      "   creating: /usr/share/nltk_data/corpora/wordnet/\r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/README  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0efab68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:35:14.264903Z",
     "iopub.status.busy": "2023-04-29T09:35:14.264553Z",
     "iopub.status.idle": "2023-04-29T09:35:14.268824Z",
     "shell.execute_reply": "2023-04-29T09:35:14.267806Z"
    },
    "papermill": {
     "duration": 0.011318,
     "end_time": "2023-04-29T09:35:14.270909",
     "exception": false,
     "start_time": "2023-04-29T09:35:14.259591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2004862",
   "metadata": {
    "papermill": {
     "duration": 0.003438,
     "end_time": "2023-04-29T09:35:14.277887",
     "exception": false,
     "start_time": "2023-04-29T09:35:14.274449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# <font color=green>Preprocess the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bae428d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:35:14.286369Z",
     "iopub.status.busy": "2023-04-29T09:35:14.286084Z",
     "iopub.status.idle": "2023-04-29T09:35:19.131132Z",
     "shell.execute_reply": "2023-04-29T09:35:19.130083Z"
    },
    "papermill": {
     "duration": 4.852163,
     "end_time": "2023-04-29T09:35:19.133643",
     "exception": false,
     "start_time": "2023-04-29T09:35:14.281480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataFrame with Test data\n",
    "test_df = pd.read_csv(f'/kaggle/input/quora-insincere-questions-classification/test.csv')\n",
    "# DataFrame with Train Data\n",
    "train_df = pd.read_csv(f'/kaggle/input/quora-insincere-questions-classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f5cc442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:35:19.142687Z",
     "iopub.status.busy": "2023-04-29T09:35:19.142389Z",
     "iopub.status.idle": "2023-04-29T09:35:19.148640Z",
     "shell.execute_reply": "2023-04-29T09:35:19.147648Z"
    },
    "papermill": {
     "duration": 0.013178,
     "end_time": "2023-04-29T09:35:19.150810",
     "exception": false,
     "start_time": "2023-04-29T09:35:19.137632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  The Function for text preprocessing\n",
    "def tokenize_string(text):\n",
    "\n",
    "    # Before lemmatizing replace all constructions with normal words\n",
    "#     text_upd = contractions.fix(text)\n",
    "\n",
    "    # Tokenize the data and use only lower letters\n",
    "    words = word_tokenize(text.lower())\n",
    "    \n",
    "    # Create a lemmatizer object\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(word, pos = \"v\") for word in words] \n",
    "    \n",
    "    # # Get rid of punctuation\n",
    "    words = [word for word in lemmas if word not in string.punctuation]\n",
    "    \n",
    "    # Remove stop words\n",
    "    # Stop words corpus (179 in total)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd2cdcb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:35:19.159545Z",
     "iopub.status.busy": "2023-04-29T09:35:19.159279Z",
     "iopub.status.idle": "2023-04-29T09:45:59.213399Z",
     "shell.execute_reply": "2023-04-29T09:45:59.212320Z"
    },
    "papermill": {
     "duration": 640.061776,
     "end_time": "2023-04-29T09:45:59.216306",
     "exception": false,
     "start_time": "2023-04-29T09:35:19.154530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have just started updatind test_df\n",
      "I have just started updatind train_df\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the series for test data\n",
    "print('I have just started updatind test_df')\n",
    "test_df['Preprocessed_text'] = test_df.question_text.apply(tokenize_string)\n",
    "\n",
    "# Tokenizing the series for train data\n",
    "print('I have just started updatind train_df')\n",
    "train_df['Preprocessed_text'] = train_df.question_text.apply(tokenize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c632c427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:45:59.226350Z",
     "iopub.status.busy": "2023-04-29T09:45:59.225720Z",
     "iopub.status.idle": "2023-04-29T09:45:59.242146Z",
     "shell.execute_reply": "2023-04-29T09:45:59.241032Z"
    },
    "papermill": {
     "duration": 0.024274,
     "end_time": "2023-04-29T09:45:59.245014",
     "exception": false,
     "start_time": "2023-04-29T09:45:59.220740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>Preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "      <td>[many, women, become, rude, arrogant, get, lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "      <td>[apply, rv, college, engineer, bms, college, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "      <td>[really, like, nurse, practitioner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "      <td>[entrepreneurs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "      <td>[education, really, make, good, people, nowadays]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...   \n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...   \n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...   \n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?   \n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?   \n",
       "\n",
       "                                   Preprocessed_text  \n",
       "0  [many, women, become, rude, arrogant, get, lit...  \n",
       "1  [apply, rv, college, engineer, bms, college, e...  \n",
       "2                [really, like, nurse, practitioner]  \n",
       "3                                    [entrepreneurs]  \n",
       "4  [education, really, make, good, people, nowadays]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb7f64f",
   "metadata": {
    "papermill": {
     "duration": 0.003902,
     "end_time": "2023-04-29T09:45:59.253164",
     "exception": false,
     "start_time": "2023-04-29T09:45:59.249262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# <font color=green>Creating baseline model based on Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edfa0a5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:45:59.262723Z",
     "iopub.status.busy": "2023-04-29T09:45:59.262431Z",
     "iopub.status.idle": "2023-04-29T09:46:00.072482Z",
     "shell.execute_reply": "2023-04-29T09:46:00.071317Z"
    },
    "papermill": {
     "duration": 0.817671,
     "end_time": "2023-04-29T09:46:00.074973",
     "exception": false,
     "start_time": "2023-04-29T09:45:59.257302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['text'] = train_df.Preprocessed_text.apply(lambda x: ' '.join(x))\n",
    "test_df['text'] = test_df.Preprocessed_text.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4617ab4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:46:00.085833Z",
     "iopub.status.busy": "2023-04-29T09:46:00.084875Z",
     "iopub.status.idle": "2023-04-29T09:46:00.089810Z",
     "shell.execute_reply": "2023-04-29T09:46:00.088808Z"
    },
    "papermill": {
     "duration": 0.012504,
     "end_time": "2023-04-29T09:46:00.091984",
     "exception": false,
     "start_time": "2023-04-29T09:46:00.079480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78556af9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:46:00.101582Z",
     "iopub.status.busy": "2023-04-29T09:46:00.101299Z",
     "iopub.status.idle": "2023-04-29T09:46:14.552646Z",
     "shell.execute_reply": "2023-04-29T09:46:14.551603Z"
    },
    "papermill": {
     "duration": 14.45923,
     "end_time": "2023-04-29T09:46:14.555405",
     "exception": false,
     "start_time": "2023-04-29T09:46:00.096175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorize the sentences\n",
    "X_train = vectorizer.fit_transform(train_df['text'])\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "y_train = train_df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c0869be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:46:14.566193Z",
     "iopub.status.busy": "2023-04-29T09:46:14.565599Z",
     "iopub.status.idle": "2023-04-29T09:46:34.997981Z",
     "shell.execute_reply": "2023-04-29T09:46:34.996536Z"
    },
    "papermill": {
     "duration": 20.441758,
     "end_time": "2023-04-29T09:46:35.001724",
     "exception": false,
     "start_time": "2023-04-29T09:46:14.559966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train a logistic regression model on the vectorized data\n",
    "clf = LogisticRegression(random_state=0, solver='liblinear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55d3c399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:46:35.030402Z",
     "iopub.status.busy": "2023-04-29T09:46:35.029502Z",
     "iopub.status.idle": "2023-04-29T09:46:35.047713Z",
     "shell.execute_reply": "2023-04-29T09:46:35.046773Z"
    },
    "papermill": {
     "duration": 0.033151,
     "end_time": "2023-04-29T09:46:35.050061",
     "exception": false,
     "start_time": "2023-04-29T09:46:35.016910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a prediction on new data\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e531cb7",
   "metadata": {
    "papermill": {
     "duration": 0.004431,
     "end_time": "2023-04-29T09:46:35.058958",
     "exception": false,
     "start_time": "2023-04-29T09:46:35.054527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "# <font color=green>Making the final file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58129910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T09:46:35.068708Z",
     "iopub.status.busy": "2023-04-29T09:46:35.068403Z",
     "iopub.status.idle": "2023-04-29T09:46:35.326672Z",
     "shell.execute_reply": "2023-04-29T09:46:35.325539Z"
    },
    "papermill": {
     "duration": 0.266175,
     "end_time": "2023-04-29T09:46:35.329432",
     "exception": false,
     "start_time": "2023-04-29T09:46:35.063257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'qid': test_df.qid, 'prediction': y_pred}).set_index('qid').to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 694.225049,
   "end_time": "2023-04-29T09:46:37.160884",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-29T09:35:02.935835",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
