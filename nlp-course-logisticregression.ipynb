{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install contractions","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:28:50.569591Z","iopub.execute_input":"2023-04-25T19:28:50.570009Z","iopub.status.idle":"2023-04-25T19:29:04.926364Z","shell.execute_reply.started":"2023-04-25T19:28:50.569975Z","shell.execute_reply":"2023-04-25T19:29:04.924921Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting contractions\n  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\nCollecting textsearch>=0.0.21\n  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\nCollecting pyahocorasick\n  Downloading pyahocorasick-2.0.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (101 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting anyascii\n  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\nSuccessfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!python3 -m nltk.downloader wordnet","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:29:11.132827Z","iopub.execute_input":"2023-04-25T19:29:11.133488Z","iopub.status.idle":"2023-04-25T19:29:13.903439Z","shell.execute_reply.started":"2023-04-25T19:29:11.133440Z","shell.execute_reply":"2023-04-25T19:29:13.901828Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:29:19.330932Z","iopub.execute_input":"2023-04-25T19:29:19.331365Z","iopub.status.idle":"2023-04-25T19:29:20.778603Z","shell.execute_reply.started":"2023-04-25T19:29:19.331328Z","shell.execute_reply":"2023-04-25T19:29:20.777488Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Libraries to drop english words and tokenize the text\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.corpus import wordnet\n\nimport contractions\nimport string\n\n# Libraries for TF-IDF model and Logistic Regression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, roc_auc_score\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-25T19:29:25.054454Z","iopub.execute_input":"2023-04-25T19:29:25.054913Z","iopub.status.idle":"2023-04-25T19:29:25.749143Z","shell.execute_reply.started":"2023-04-25T19:29:25.054873Z","shell.execute_reply":"2023-04-25T19:29:25.747769Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n/kaggle/input/quora-insincere-questions-classification/embeddings.zip\n/kaggle/input/quora-insincere-questions-classification/train.csv\n/kaggle/input/quora-insincere-questions-classification/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"nltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:29:28.296328Z","iopub.execute_input":"2023-04-25T19:29:28.296768Z","iopub.status.idle":"2023-04-25T19:29:28.388722Z","shell.execute_reply.started":"2023-04-25T19:29:28.296732Z","shell.execute_reply":"2023-04-25T19:29:28.387789Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# <font color=green>Preprocess the data</font>","metadata":{}},{"cell_type":"code","source":"# DataFrame with Test data\ntest_df = pd.read_csv(f'/kaggle/input/quora-insincere-questions-classification/test.csv')\n# DataFrame with Train Data\ntrain_df = pd.read_csv(f'/kaggle/input/quora-insincere-questions-classification/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:29:31.674766Z","iopub.execute_input":"2023-04-25T19:29:31.675165Z","iopub.status.idle":"2023-04-25T19:29:38.024058Z","shell.execute_reply.started":"2023-04-25T19:29:31.675131Z","shell.execute_reply":"2023-04-25T19:29:38.022925Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#  The Function for text preprocessing\ndef tokenize_string(text):\n\n    # Before lemmatizing replace all constructions with normal words\n    text_upd = contractions.fix(text)\n\n    # Tokenize the data and use only lower letters\n    words = word_tokenize(text_upd.lower())\n    \n    # Create a lemmatizer object\n    lemmatizer = WordNetLemmatizer()\n    lemmas = [lemmatizer.lemmatize(word, pos = \"v\") for word in words] \n    \n    # # Get rid of punctuation\n    words = [word for word in lemmas if word not in string.punctuation]\n    \n    # Remove stop words\n    # Stop words corpus (179 in total)\n    stop_words = set(stopwords.words('english'))\n    words = [word for word in words if word not in stop_words]\n    \n    return words","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:29:41.984815Z","iopub.execute_input":"2023-04-25T19:29:41.985269Z","iopub.status.idle":"2023-04-25T19:29:41.993788Z","shell.execute_reply.started":"2023-04-25T19:29:41.985230Z","shell.execute_reply":"2023-04-25T19:29:41.992802Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Tokenizing the series for test data\ntest_df['Preprocessed_text'] = test_df.question_text.apply(tokenize_string)\n\n# Tokenizing the series for train data\ntrain_df['Preprocessed_text'] = train_df.question_text.apply(tokenize_string)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:29:47.404415Z","iopub.execute_input":"2023-04-25T19:29:47.404846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:25:54.331289Z","iopub.execute_input":"2023-04-25T19:25:54.331718Z","iopub.status.idle":"2023-04-25T19:25:54.347245Z","shell.execute_reply.started":"2023-04-25T19:25:54.331682Z","shell.execute_reply":"2023-04-25T19:25:54.345454Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"                    qid                                      question_text  \\\n0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...   \n1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...   \n2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...   \n3  000086e4b7e1c7146103                             Who are entrepreneurs?   \n4  0000c4c3fbe8785a3090   Is education really making good people nowadays?   \n\n                                   Preprocessed_text  \\\n0  [many, women, become, rude, arrogant, get, lit...   \n1  [apply, rv, college, engineer, bms, college, e...   \n2                [really, like, nurse, practitioner]   \n3                                    [entrepreneurs]   \n4  [education, really, make, good, people, nowadays]   \n\n                                                text  \n0  many women become rude arrogant get little bit...  \n1  apply rv college engineer bms college engineer...  \n2                     really like nurse practitioner  \n3                                      entrepreneurs  \n4         education really make good people nowadays  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>Preprocessed_text</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000163e3ea7c7a74cd7</td>\n      <td>Why do so many women become so rude and arroga...</td>\n      <td>[many, women, become, rude, arrogant, get, lit...</td>\n      <td>many women become rude arrogant get little bit...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00002bd4fb5d505b9161</td>\n      <td>When should I apply for RV college of engineer...</td>\n      <td>[apply, rv, college, engineer, bms, college, e...</td>\n      <td>apply rv college engineer bms college engineer...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00007756b4a147d2b0b3</td>\n      <td>What is it really like to be a nurse practitio...</td>\n      <td>[really, like, nurse, practitioner]</td>\n      <td>really like nurse practitioner</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000086e4b7e1c7146103</td>\n      <td>Who are entrepreneurs?</td>\n      <td>[entrepreneurs]</td>\n      <td>entrepreneurs</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000c4c3fbe8785a3090</td>\n      <td>Is education really making good people nowadays?</td>\n      <td>[education, really, make, good, people, nowadays]</td>\n      <td>education really make good people nowadays</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# <font color=green>Creating baseline model based on Logistic Regression</font>","metadata":{}},{"cell_type":"code","source":"train_df['text'] = train_df.Preprocessed_text.apply(lambda x: ' '.join(x))\ntest_df['text'] = test_df.Preprocessed_text.apply(lambda x: ' '.join(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the TF-IDF vectorizer\nvectorizer = TfidfVectorizer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vectorize the sentences\nX_train = vectorizer.fit_transform(train_df['text'])\nX_test = vectorizer.fit_transform(test_df['text'])\n\ny_train = train_df.target.values","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:26:05.190937Z","iopub.execute_input":"2023-04-25T19:26:05.191378Z","iopub.status.idle":"2023-04-25T19:26:23.215622Z","shell.execute_reply.started":"2023-04-25T19:26:05.191339Z","shell.execute_reply":"2023-04-25T19:26:23.214212Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# test_size = 0.2 # proportion of the data to include in the test set\n# random_state = 18 # random seed for reproducibility\n# X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y_train, \n#                                                         test_size=test_size, random_state=random_state)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:18:22.321915Z","iopub.execute_input":"2023-04-25T19:18:22.322416Z","iopub.status.idle":"2023-04-25T19:18:22.622072Z","shell.execute_reply.started":"2023-04-25T19:18:22.322372Z","shell.execute_reply":"2023-04-25T19:18:22.620773Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Train a logistic regression model on the vectorized data\nclf = LogisticRegression(random_state=0, solver='liblinear').fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:26:44.677735Z","iopub.execute_input":"2023-04-25T19:26:44.678240Z","iopub.status.idle":"2023-04-25T19:27:07.906461Z","shell.execute_reply.started":"2023-04-25T19:26:44.678192Z","shell.execute_reply":"2023-04-25T19:27:07.905368Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Make a prediction on new data\ny_pred = clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:27:20.091287Z","iopub.execute_input":"2023-04-25T19:27:20.091725Z","iopub.status.idle":"2023-04-25T19:27:20.123631Z","shell.execute_reply.started":"2023-04-25T19:27:20.091689Z","shell.execute_reply":"2023-04-25T19:27:20.121686Z"},"trusted":true},"execution_count":52,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/523366572.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make a prediction on new data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: X has 94207 features, but LogisticRegression is expecting 185608 features as input."],"ename":"ValueError","evalue":"X has 94207 features, but LogisticRegression is expecting 185608 features as input.","output_type":"error"}]},{"cell_type":"code","source":"print('Classification report:\\n\\n', classification_report(y_test1, y_pred))\nprint(\"\\nROC AUC score:\", round(roc_auc_score(y_test1, y_pred), 3))","metadata":{"execution":{"iopub.status.busy":"2023-04-25T19:22:09.245402Z","iopub.execute_input":"2023-04-25T19:22:09.245945Z","iopub.status.idle":"2023-04-25T19:22:09.633361Z","shell.execute_reply.started":"2023-04-25T19:22:09.245903Z","shell.execute_reply":"2023-04-25T19:22:09.631638Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Classification report:\n\n               precision    recall  f1-score   support\n\n           0       0.96      0.99      0.97    244845\n           1       0.70      0.37      0.48     16380\n\n    accuracy                           0.95    261225\n   macro avg       0.83      0.68      0.73    261225\nweighted avg       0.94      0.95      0.94    261225\n\n\nROC AUC score: 0.68\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}