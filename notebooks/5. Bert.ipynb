{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of work <a id = \"plan\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "[1. Downloading and preparing data](#1.)<br>\n",
    "[2. Train model](#2.)<br>\n",
    "[3. Final testing](#3.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import asarray\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Downloading and preparing data <a id = \"1.\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to plan](#plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = \"./Data\"\n",
    "MAX_LEN = 134\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.003\n",
    "MODEL_NAME = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(PATH, \"train.csv\"))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1306122 entries, 0 to 1306121\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   qid            1306122 non-null  object\n",
      " 1   question_text  1306122 non-null  object\n",
      " 2   target         1306122 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 29.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(os.path.join(PATH, \"test.csv\"))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 375806 entries, 0 to 375805\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   qid            375806 non-null  object\n",
      " 1   question_text  375806 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the data into training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_split(data: pd.DataFrame, train_frac=0.85):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test parts, stratifying by labels.\n",
    "    :param data: dataset to split\n",
    "    :param train_frac: proportion of train examples\n",
    "    :return: texts and labels for each split\n",
    "    \"\"\"\n",
    "    train_data, test_data = None, None\n",
    "    train_texts = []\n",
    "    test_texts = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    for label in data['target'].unique():\n",
    "        texts = data[data.target == label].question_text\n",
    "        n_train = int(len(texts) * train_frac)\n",
    "        n_test = len(texts) - n_train\n",
    "        train_texts.extend(texts[:n_train])\n",
    "        test_texts.extend(texts[n_train:])\n",
    "        train_labels += [label] * n_train\n",
    "        test_labels += [label] * n_test\n",
    "        train_data = {\n",
    "            'question_text': train_texts,\n",
    "            'target': train_labels\n",
    "        }\n",
    "        test_data = {\n",
    "            'question_text': test_texts,\n",
    "            'target': test_labels\n",
    "        }\n",
    "    return pd.DataFrame(train_data), pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_split, val_split = train_test_split(train_data, train_frac=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the tokenizer from the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME, truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuoraDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_seq_len):\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe['question_text']\n",
    "        self.targets = None\n",
    "        if 'target' in dataframe:\n",
    "            self.targets = dataframe['target']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_seq_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        if self.targets is not None:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'targets': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = QuoraDataset(train_split, tokenizer, MAX_LEN)\n",
    "val_dataset = QuoraDataset(val_split, tokenizer, MAX_LEN)\n",
    "test_dataset = QuoraDataset(test_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 0\n",
    "}\n",
    "\n",
    "test_params = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 0\n",
    "}\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, **train_params)\n",
    "val_dataloader = DataLoader(val_dataset, **test_params)\n",
    "test_dataloader = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train model <a id = \"2.\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to plan](#plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertModel\n",
    "# from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "class DistilBertForClassification(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, distil_bert_path: str, config: Dict):\n",
    "        super(DistilBertForClassification, self).__init__()\n",
    "        self.model_name = distil_bert_path\n",
    "        self.config = config\n",
    "        self.n_classes = config['num_classes']\n",
    "        self.dropout_rate = config['dropout_rate']\n",
    "        # self.bert = AutoModelForSequenceClassification.from_pretrained(distil_bert_path)\n",
    "        self.bert = DistilBertModel.from_pretrained(distil_bert_path)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 128)\n",
    "        self.dropout = torch.nn.Dropout(self.dropout_rate)\n",
    "        self.classifier = torch.nn.Linear(128, self.n_classes)\n",
    "        # self.bert.tie_weights()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask,):\n",
    "        output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        hidden_state = output[0]\n",
    "        hidden_state = hidden_state[:, 0]\n",
    "        hidden_state = self.pre_classifier(hidden_state)\n",
    "        hidden_state = torch.nn.ReLU()(hidden_state)\n",
    "        hidden_state = self.dropout(hidden_state)\n",
    "        output = self.classifier(hidden_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"num_classes\": 2,\n",
    "    \"dropout_rate\": 0.1\n",
    "}\n",
    "model = DistilBertForClassification(\n",
    "    MODEL_NAME,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.n_epochs = config['n_epochs']\n",
    "        self.optimizer = None\n",
    "        self.opt_fn = lambda model: Adam(model.parameters(), config['lr'])\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.loss_fn = CrossEntropyLoss()\n",
    "        self.device = config['device']\n",
    "        self.verbose = config.get('verbose', True)\n",
    "\n",
    "    def fit(self, model, train_dataloader, val_dataloader):\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = self.opt_fn(model)\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': []\n",
    "        }\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            print(f\"Epoch {epoch + 1}/{self.n_epochs}\")\n",
    "            train_info = self.train_epoch(train_dataloader)\n",
    "            val_info = self.val_epoch(val_dataloader)\n",
    "            self.history['train_loss'].extend(train_info['loss'])\n",
    "            self.history['val_loss'].extend([val_info['loss']])\n",
    "            self.history['val_acc'].extend([val_info['acc']])\n",
    "        return self.model.eval()\n",
    "\n",
    "    def train_epoch(self, train_dataloader):\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        if self.verbose:\n",
    "            train_dataloader = tqdm(train_dataloader)\n",
    "        for batch in train_dataloader:\n",
    "            ids = batch['ids'].to(self.device, dtype=torch.long)\n",
    "            mask = batch['mask'].to(self.device, dtype=torch.long)\n",
    "            targets = batch['targets'].to(self.device, dtype=torch.long)\n",
    "\n",
    "            outputs = self.model(ids, mask)\n",
    "            loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss_val = loss.item()\n",
    "            if self.verbose:\n",
    "                train_dataloader.set_description(f\"Loss={loss_val:.3}\")\n",
    "            losses.append(loss_val)\n",
    "        return {'loss': losses}\n",
    "\n",
    "    def val_epoch(self, val_dataloader):\n",
    "        self.model.eval()\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        if self.verbose:\n",
    "            val_dataloader = tqdm(val_dataloader)\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                ids = batch['ids'].to(self.device, dtype=torch.long)\n",
    "                mask = batch['mask'].to(self.device, dtype=torch.long)\n",
    "                targets = batch['targets'].to(self.device, dtype=torch.long)\n",
    "                outputs = self.model(ids, mask)\n",
    "                all_logits.append(outputs)\n",
    "                all_labels.append(targets)\n",
    "        all_labels = torch.cat(all_labels).to(self.device)\n",
    "        all_logits = torch.cat(all_logits).to(self.device)\n",
    "        loss = self.loss_fn(all_logits, all_labels).item()\n",
    "        acc = (all_logits.argmax(1) == all_labels).float().mean().item()\n",
    "        print(acc)\n",
    "        if self.verbose:\n",
    "            val_dataloader.set_description(f\"Loss={loss:.3}; Acc:{acc:.3}\")\n",
    "        return {\n",
    "            'acc': acc,\n",
    "            'loss': loss\n",
    "        }\n",
    "\n",
    "    def predict(self, test_dataloader):\n",
    "        if not self.model:\n",
    "            raise RuntimeError(\"You should train the model first\")\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                ids = batch['ids'].to(self.device, dtype=torch.long)\n",
    "                mask = batch['mask'].to(self.device, dtype=torch.long)\n",
    "                outputs = self.model(ids, mask)\n",
    "                predictions.extend(outputs.argmax(1).tolist())\n",
    "        return asarray(predictions)\n",
    "    \n",
    "    def predict_probs(self, test_dataloader):\n",
    "        if not self.model:\n",
    "            raise RuntimeError(\"You should train the model first\")\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                ids = batch['ids'].to(self.device, dtype=torch.long)\n",
    "                mask = batch['mask'].to(self.device, dtype=torch.long)\n",
    "                outputs = self.model(ids, mask)\n",
    "                predictions.extend(F.softmax(outputs).tolist())\n",
    "        return asarray(predictions)\n",
    "\n",
    "    def save(self, path: str):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"You should train the model first\")\n",
    "        checkpoint = {\n",
    "            \"config\": self.model.config,\n",
    "            \"trainer_config\": self.config,\n",
    "            \"model_name\": self.model.model_name,\n",
    "            \"model_state_dict\": self.model.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: str):\n",
    "        ckpt = torch.load(path)\n",
    "        keys = [\"config\", \"trainer_config\", \"model_state_dict\"]\n",
    "        for key in keys:\n",
    "            if key not in ckpt:\n",
    "                raise RuntimeError(f\"Missing key {key} in checkpoint\")\n",
    "        new_model = DistilBertForClassification(\n",
    "            ckpt['model_name'],\n",
    "            ckpt[\"config\"]\n",
    "        )\n",
    "        new_model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        new_trainer = cls(ckpt[\"trainer_config\"])\n",
    "        new_trainer.model = new_model\n",
    "        new_trainer.model.to(new_trainer.device)\n",
    "        return new_trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89901634d0b4dc49cfc38353b6c4684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4337 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chern\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer_config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: LR,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# \"device\": \"cpu\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m      9\u001b[0m t \u001b[38;5;241m=\u001b[39m Trainer(trainer_config)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 24\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloader, val_dataloader)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m     train_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     val_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_epoch(val_dataloader)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(train_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[15], line 47\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self, train_dataloader)\u001b[0m\n\u001b[0;32m     45\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 47\u001b[0m loss_val \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m     49\u001b[0m     train_dataloader\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_val\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer_config = {\n",
    "    \"lr\": LR,\n",
    "    \"n_epochs\": 1,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # \"device\": \"cpu\"\n",
    "}\n",
    "t = Trainer(trainer_config)\n",
    "t.fit(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Final testing <a id = \"3.\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "[Back to plan](#plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = t.predict(test_dataloader)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data[\"prediction\"] = predictions \n",
    "test_data[[\"qid\", \"prediction\"]].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ce47e61e2a197e18f6178d2b52c72741babf3e522a6ab2c8e52c7be76b98a41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
