{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elizavetachefanova/Documents/Courses/NLP course/Final project\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score\n",
    "import contractions\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# from multiprocessing import Pool\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Get project path\n",
    "project_path = Path.cwd().resolve().parent.parent\n",
    "print(project_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GPU for studying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# session = tf.compat.v1.Session(config=config)\n",
    "# K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <font color=green>Preprocess the data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataFrame with Train Data\n",
    "train_df = pd.read_csv(f'{project_path}/Output/Cleaned_train_data.csv', index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <font color=green>LSTM based on Word2Vec</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  The Function for text preprocessing\n",
    "def tokenize_string(text):\n",
    "\n",
    "    # Before lemmatizing replace all constructions with normal words\n",
    "    text_upd = contractions.fix(text)\n",
    "\n",
    "    # Tokenize the data and use only lower letters\n",
    "    words = word_tokenize(text_upd.lower())\n",
    "    \n",
    "    # Create a lemmatizer object\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(word, pos = \"v\") for word in words] \n",
    "    \n",
    "    # # Get rid of punctuation\n",
    "    words = [word for word in lemmas if word not in string.punctuation]\n",
    "    \n",
    "    # Remove stop words\n",
    "    # Stop words corpus (179 in total)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have just started updatind train_df\n",
      "Time spent: 5 min,  13 sec\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the series for train data\n",
    "print('I have just started updatind train_df')\n",
    "start = time.time()\n",
    "train_df['Preprocessed_text'] = train_df.question_text.apply(tokenize_string)\n",
    "finish = time.time()\n",
    "\n",
    "print('Time spent:', int((finish - start)//60), 'min, ', round((finish - start)%60), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(f'{project_path}/Output/Cleaned_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(train_df['Preprocessed_text'], vector_size=700, window=5, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing the whole phrase instead of separate phrases\n",
    "def phrase_vector(word2vec_model, phrase):\n",
    "    phrase = [word for word in phrase if word in word2vec_model.wv.key_to_index]\n",
    "    \n",
    "    if len(phrase) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    \n",
    "    return np.mean(word2vec_model.wv[phrase], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(np.array([phrase_vector(word2vec_model, phrase) for phrase in train_df['Preprocessed_text']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = purple>Split data before studying the model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(1, X_train.shape[-1])))   \n",
    "model.add(LSTM(64, return_sequences=True))  \n",
    "model.add(LSTM(32)) \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "checkpoint_filepath = 'tmp/checkpoint/model_best.h5'\n",
    "\n",
    "model_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiDirectionalLSTM model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=(1, X_train.shape[-1])))   \n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))    \n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True))) \n",
    "model.add(Bidirectional(LSTM(32))) \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "checkpoint_filepath = 'tmp/checkpoint/model_best.h5'\n",
    "\n",
    "model_callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "model.compile(loss='BinaryFocalCrossentropy', optimizer='adam', metrics=['AUC'])\n",
    "class_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "unique_classes = np.unique(y_train)\n",
    "class_weights = {cls: 1.0/np.mean(class_weights[y_train==cls]) for cls in unique_classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29386/29388 [============================>.] - ETA: 0s - loss: 0.0105 - auc: 0.9333\n",
      "Epoch 1: val_auc improved from -inf to 0.94543, saving model to tmp/checkpoint/model_best.h5\n",
      "29388/29388 [==============================] - 506s 17ms/step - loss: 0.0105 - auc: 0.9333 - val_loss: 0.0552 - val_auc: 0.9454\n",
      "Epoch 2/10\n",
      "29387/29388 [============================>.] - ETA: 0s - loss: 0.0098 - auc: 0.9449\n",
      "Epoch 2: val_auc improved from 0.94543 to 0.94668, saving model to tmp/checkpoint/model_best.h5\n",
      "29388/29388 [==============================] - 461s 16ms/step - loss: 0.0098 - auc: 0.9449 - val_loss: 0.0563 - val_auc: 0.9467\n",
      "Epoch 3/10\n",
      "29386/29388 [============================>.] - ETA: 0s - loss: 0.0096 - auc: 0.9493\n",
      "Epoch 3: val_auc improved from 0.94668 to 0.94764, saving model to tmp/checkpoint/model_best.h5\n",
      "29388/29388 [==============================] - 415s 14ms/step - loss: 0.0096 - auc: 0.9493 - val_loss: 0.0578 - val_auc: 0.9476\n",
      "Epoch 4/10\n",
      "29388/29388 [==============================] - ETA: 0s - loss: 0.0094 - auc: 0.9525\n",
      "Epoch 4: val_auc improved from 0.94764 to 0.94795, saving model to tmp/checkpoint/model_best.h5\n",
      "29388/29388 [==============================] - 432s 15ms/step - loss: 0.0094 - auc: 0.9525 - val_loss: 0.0535 - val_auc: 0.9479\n",
      "Epoch 5/10\n",
      "29386/29388 [============================>.] - ETA: 0s - loss: 0.0092 - auc: 0.9558\n",
      "Epoch 5: val_auc did not improve from 0.94795\n",
      "29388/29388 [==============================] - 392s 13ms/step - loss: 0.0092 - auc: 0.9558 - val_loss: 0.0590 - val_auc: 0.9477\n",
      "Epoch 6/10\n",
      "29387/29388 [============================>.] - ETA: 0s - loss: 0.0090 - auc: 0.9586\n",
      "Epoch 6: val_auc improved from 0.94795 to 0.94807, saving model to tmp/checkpoint/model_best.h5\n",
      "29388/29388 [==============================] - 448s 15ms/step - loss: 0.0090 - auc: 0.9586 - val_loss: 0.0542 - val_auc: 0.9481\n",
      "Epoch 7/10\n",
      "29387/29388 [============================>.] - ETA: 0s - loss: 0.0088 - auc: 0.9615\n",
      "Epoch 7: val_auc did not improve from 0.94807\n",
      "29388/29388 [==============================] - 449s 15ms/step - loss: 0.0088 - auc: 0.9615 - val_loss: 0.0534 - val_auc: 0.9471\n",
      "Epoch 8/10\n",
      "29387/29388 [============================>.] - ETA: 0s - loss: 0.0086 - auc: 0.9644\n",
      "Epoch 8: val_auc did not improve from 0.94807\n",
      "29388/29388 [==============================] - 412s 14ms/step - loss: 0.0086 - auc: 0.9644 - val_loss: 0.0553 - val_auc: 0.9469\n",
      "Epoch 9/10\n",
      "29385/29388 [============================>.] - ETA: 0s - loss: 0.0084 - auc: 0.9669\n",
      "Epoch 9: val_auc did not improve from 0.94807\n",
      "29388/29388 [==============================] - 424s 14ms/step - loss: 0.0084 - auc: 0.9669 - val_loss: 0.0600 - val_auc: 0.9447\n",
      "Epoch 10/10\n",
      "29387/29388 [============================>.] - ETA: 0s - loss: 0.0081 - auc: 0.9694\n",
      "Epoch 10: val_auc did not improve from 0.94807\n",
      "29388/29388 [==============================] - 443s 15ms/step - loss: 0.0081 - auc: 0.9694 - val_loss: 0.0599 - val_auc: 0.9448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x296b452b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, \n",
    "          class_weight=class_weights, callbacks = model_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the tests dataset for predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with Test data\n",
    "# test_df = pd.read_csv(f'/kaggle/input/quora-insincere-questions-classification/test.csv')\n",
    "# print('I have just started updatind test_df')\n",
    "# start = time.time()\n",
    "# test_df['Preprocessed_text'] = test_df.question_text.apply(tokenize_string)\n",
    "# finish = time.time()\n",
    "\n",
    "# print('Time spent:', int((finish - start)//60), 'min, ', round((finish - start)%60), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = np.expand_dims(np.array([phrase_vector(word2vec_model, phrase) \n",
    "#                                    for phrase in test_df['Preprocessed_text']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del word2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8164/8164 [==============================] - 39s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the array\n",
    "preds = predictions.flatten()\n",
    "\n",
    "# find the 95th percentile value\n",
    "threshold = np.percentile(preds, 93)\n",
    "\n",
    "# create a new array where values higher than the threshold are 1 and others are 0\n",
    "y_pred = np.where(preds > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97    245063\n",
      "           1       0.56      0.64      0.60     16162\n",
      "\n",
      "    accuracy                           0.95    261225\n",
      "   macro avg       0.77      0.80      0.79    261225\n",
      "weighted avg       0.95      0.95      0.95    261225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8029814768182395\n"
     ]
    }
   ],
   "source": [
    "print(balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <font color=green>Making the final file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'qid': test_df.qid, 'prediction': y_pred}).set_index('qid').to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
